import streamlit as st
import pandas as pd
import unicodedata
import re
import os
from streamlit_gsheets import GSheetsConnection

# === ãƒšãƒ¼ã‚¸è¨­å®š ===
st.set_page_config(page_title="å·¥äº‹å®Ÿç¸¾ç®¡ç†DB", layout="wide")

# ==========================================
# ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šï¼ˆç°¡æ˜“ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ï¼‰
# ==========================================
def check_password():
    """ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ãŒé€šã£ã¦ã„ãªã‘ã‚Œã°å…¥åŠ›ã‚’æ±‚ã‚ã€åœæ­¢ã™ã‚‹"""
    if "authenticated" not in st.session_state:
        st.session_state.authenticated = False

    # èªè¨¼æ¸ˆã¿ãªã‚‰ä½•ã‚‚ã—ãªã„
    if st.session_state.authenticated:
        return True

    # ç”»é¢è¡¨ç¤º
    st.title("ğŸ”’ ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™")
    
    # secrets.tomlã«ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆã®å®‰å…¨ç­–
    if "PASSWORD" not in st.secrets:
        st.error("ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæœªè¨­å®šã§ã™ï¼‰")
        st.stop()

    password_input = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    
    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
        if password_input == st.secrets["PASSWORD"]:
            st.session_state.authenticated = True
            st.rerun()  # ç”»é¢ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ¡ã‚¤ãƒ³å‡¦ç†ã¸
        else:
            st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™")
    
    return False

# èªè¨¼ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œï¼ˆå¤±æ•—ã¾ãŸã¯æœªå…¥åŠ›ãªã‚‰ã“ã“ã§ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒæ­¢ã¾ã‚‹ï¼‰
if not check_password():
    st.stop()


# ==========================================
# ğŸš€ ã“ã“ã‹ã‚‰ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª
# ==========================================

# === Google Sheets ã®å„ã‚·ãƒ¼ãƒˆå ===
KOUJI_SHEET = "dobokudata"      # IDã§ã¯ãªãåå‰ã«ã™ã‚‹
ENGINEER_SHEET = "engineer_list" # IDã§ã¯ãªãåå‰ã«ã™ã‚‹

st.title("ğŸ“‹ æŠ€è¡“è€…ãƒ»å·¥äº‹å®Ÿç¸¾ç®¡ç†ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
st.sidebar.success("âœ… ãƒ­ã‚°ã‚¤ãƒ³ä¸­")

# === GSheets æ¥ç¶š ===
try:
    conn = st.connection("gsheets", type=GSheetsConnection)
except Exception as e:
    st.error(f"âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# =========================
# ãƒ‡ãƒ¼ã‚¿å‡¦ç†ç”¨é–¢æ•°
# =========================
def normalize_text(text):
    if pd.isnull(text):
        return ""
    text = str(text)
    text = unicodedata.normalize("NFKC", text)
    return text.lower()

def clean_string_for_match(text):
    if pd.isnull(text):
        return ""
    norm = normalize_text(text)
    return norm.replace(" ", "").replace("ã€€", "")

def process_price_data(x):
    if pd.isnull(x) or str(x).strip() == "":
        return 0
    s_clean = normalize_text(x)
    s_clean = s_clean.replace(",", "").replace("å††", "")
    numbers = re.findall(r"\d+", s_clean)
    if not numbers:
        return 0
    valid_nums = []
    for n in numbers:
        if len(n) > 15:
            continue
        valid_nums.append(int(n))
    if not valid_nums:
        return 0
    return max(valid_nums)

# =========================
# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ãƒ»ä¿å­˜
# =========================
# =========================
# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ãƒ»ä¿å­˜
# =========================
@st.cache_data(ttl=600)
def load_data():
    # --- å·¥äº‹ãƒ‡ãƒ¼ã‚¿ ---
    # ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œã«çµ¶å¯¾å¿…è¦ãªã€Œé‡è¦ã‚«ãƒ©ãƒ ã€
    core_k_cols = [
        'å·¥äº‹å', 'å·¥äº‹æ¦‚è¦ï¼ˆä¸»ãªå·¥ç¨®ã€è¦æ ¼ã€æ•°é‡ï¼‰', 'å·¥ç¨®å', 'é‡‘é¡', 
        'ç«£å·¥æ—¥', 'ç€æ‰‹æ—¥', 'ç¾å ´ä»£ç†äºº', 'ç›£ç†æŠ€è¡“è€…', 'ä¸»ä»»æŠ€è¡“è€…', 
        'ç¾å ´æ‹…å½“è€…ï¼‘', 'ç¾å ´æ‹…å½“è€…ï¼’', 'å·¥äº‹å ´æ‰€', 'JVæ¯”ç‡', 'ç‰¹è¨˜å·¥æ³•'
    ]

    try:
        # ã‚·ãƒ¼ãƒˆã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾èª­ã¿è¾¼ã‚€ï¼ˆã“ã‚Œã§å‹æ‰‹ã«è¿½åŠ ã—ãŸåˆ—ã‚‚èª­ã‚ã‚‹ï¼‰
        df_k = conn.read(worksheet=KOUJI_SHEET, ttl=0)
    except Exception as e:
        st.error(f"å·¥äº‹ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        df_k = pd.DataFrame()

    # ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®å ´åˆã®ä¿é™º
    if df_k.empty:
        df_k = pd.DataFrame(columns=core_k_cols)
    
    # é‡è¦ã‚«ãƒ©ãƒ ãŒèª¤ã£ã¦æ¶ˆã•ã‚Œã¦ã„ãŸå ´åˆã€ç©ºåˆ—ã¨ã—ã¦å¾©æ´»ã•ã›ã‚‹ï¼ˆã‚¨ãƒ©ãƒ¼é˜²æ­¢ï¼‰
    for c in core_k_cols:
        if c not in df_k.columns:
            df_k[c] = ""

    # æ—¥ä»˜åˆ—ã®å‡¦ç†ï¼ˆ"æ—¥"ãŒå«ã¾ã‚Œã‚‹åˆ—ã¯ã™ã¹ã¦æ—¥ä»˜å‹ã«å¤‰æ›ï¼‰
    for col in df_k.columns:
        if "æ—¥" in col:
            df_k[col] = pd.to_datetime(df_k[col], errors="coerce")


    # --- æŠ€è¡“è€…ãƒ‡ãƒ¼ã‚¿ ---
    core_e_cols = [
        'æ°å', 'ä¿æœ‰è³‡æ ¼', 'è³‡æ ¼', 'åœ¨ç±çŠ¶æ³', 'æŠ€è¡“è€…ID',
        'ç›£ç†æŠ€è¡“è€…è³‡æ ¼è€…è¨¼ç•ªå·', 'äº¤ä»˜æ—¥', 'æœ‰åŠ¹æœŸé™æ—¥', 'ç›£ç†æŠ€è¡“è€…è¬›ç¿’ä¿®äº†å¹´æœˆæ—¥', 'æœ€æ–°æ›´æ–°æ—¥'
    ]
        
    try:
        df_e = conn.read(worksheet=ENGINEER_SHEET, ttl=0)
    except Exception as e:
        st.error(f"æŠ€è¡“è€…ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        df_e = pd.DataFrame()

    if df_e.empty:
        df_e = pd.DataFrame(columns=core_e_cols)

    # é‡è¦ã‚«ãƒ©ãƒ ã®ç¢ºä¿
    for col in core_e_cols:
        if col not in df_e.columns:
            if col == 'åœ¨ç±çŠ¶æ³':
                df_e[col] = True
            else:
                df_e[col] = ""

    # æ—¥ä»˜å‡¦ç†
    for col in df_e.columns:
        if "æ—¥" in col:
            df_e[col] = pd.to_datetime(df_e[col], errors="coerce")

    # å‹å¤‰æ›å‡¦ç†
    if "æŠ€è¡“è€…ID" in df_e.columns:
        df_e["æŠ€è¡“è€…ID"] = df_e["æŠ€è¡“è€…ID"].fillna("").astype(str)
        df_e["æŠ€è¡“è€…ID"] = df_e["æŠ€è¡“è€…ID"].str.replace(r"\.0$", "", regex=True)
        df_e["æŠ€è¡“è€…ID"] = df_e["æŠ€è¡“è€…ID"].replace("nan", "")

    if "åœ¨ç±çŠ¶æ³" in df_e.columns:
        df_e["åœ¨ç±çŠ¶æ³"] = df_e["åœ¨ç±çŠ¶æ³"].fillna(True).astype(bool)

    return df_k, df_e
# =========================
# ä¿å­˜ç”¨é–¢æ•°ï¼ˆã‚·ãƒ¼ãƒˆã”ã¨ã«åˆ†å‰²ï¼‰
# =========================
def save_kouji(df):
    """å·¥äº‹ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æ›´æ–°ã™ã‚‹"""
    try:
        conn.update(worksheet=KOUJI_SHEET, data=df)
        return True
    except Exception as e:
        st.error(f"å·¥äº‹ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False

def save_engineer(df):
    """æŠ€è¡“è€…ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æ›´æ–°ã™ã‚‹"""
    try:
        conn.update(worksheet=ENGINEER_SHEET, data=df)
        return True
    except Exception as e:
        st.error(f"æŠ€è¡“è€…ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df_kouji_raw, df_eng_raw = load_data()

# =========================
# ã‚¿ãƒ–ç”»é¢æ§‹æˆ
# =========================
tab1, tab2, tab3 = st.tabs(["ğŸ” å®Ÿç¸¾æ¤œç´¢", "âœï¸ å·¥äº‹ãƒ‡ãƒ¼ã‚¿ç™»éŒ²ãƒ»ç·¨é›†", "ğŸ‘¤ æŠ€è¡“è€…ç™»éŒ²ãƒ»ç·¨é›†"])

# --- ã‚¿ãƒ–1: æ¤œç´¢ï¼ˆæŠ€è¡“è€…ãƒ™ãƒ¼ã‚¹ Ã— å®Ÿç¸¾æ¡ä»¶ï¼‰ ---
with tab1:
    df_search = df_kouji_raw.copy()
    
    # 1. é‡‘é¡ã®æ•°å€¤åŒ–å‡¦ç†
    price_cols = [c for c in df_search.columns if "é‡‘é¡" in c]
    if price_cols:
        target_col = price_cols[0]
        df_search["search_price"] = df_search[target_col].apply(process_price_data)
    else:
        df_search["search_price"] = 0

    # 2. å¹´ã®æ•°å€¤åŒ–å‡¦ç†
    if "ç«£å·¥æ—¥" in df_search.columns:
        df_search["ç«£å·¥æ—¥_dt"] = pd.to_datetime(df_search["ç«£å·¥æ—¥"], errors="coerce")
        df_search["ç«£å·¥å¹´_val"] = df_search["ç«£å·¥æ—¥_dt"].dt.year.fillna(0).astype(int)
    else:
        df_search["ç«£å·¥å¹´_val"] = 0

    # å…¨æ–‡æ¤œç´¢ç”¨ã‚«ãƒ©ãƒ ä½œæˆ
    def combine_all_columns(row):
        text = ""
        for val in row.values:
            if pd.notnull(val):
                text += normalize_text(val) + " "
        return text

    if not df_search.empty:
        df_search['full_text_search'] = df_search.apply(combine_all_columns, axis=1)
    else:
        df_search['full_text_search'] = ""

    # ========================================================
    # ã€å¤‰æ›´ç‚¹ã€‘åœ¨ç±æŠ€è¡“è€…ãƒªã‚¹ãƒˆã®æº–å‚™ï¼ˆéƒ¨åˆ†ä¸€è‡´æ¤œç´¢ç”¨ï¼‰
    # ========================================================
    engineer_map = {} # (æ¤œç´¢ç”¨æ­£è¦åŒ–å) -> è³‡æ ¼
    active_engineer_list = [] # æ¤œç´¢ãƒ«ãƒ¼ãƒ—ã§å›ã™ãŸã‚ã®ãƒªã‚¹ãƒˆ [(æ­£è¦åŒ–å, è¡¨ç¤ºå), ...]

    if not df_eng_raw.empty:
        # åœ¨ç±è€…ã®ã¿æŠ½å‡ºï¼ˆé€€è·è€…ã¯ã“ã“ã§é™¤å¤–ã•ã‚Œã‚‹ï¼‰
        active_engineers_df = df_eng_raw[df_eng_raw['åœ¨ç±çŠ¶æ³'] == True]
    else:
        active_engineers_df = pd.DataFrame()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¡¨ç¤ºç”¨ãƒªã‚¹ãƒˆ
    active_names = []
    active_quals = []
    name_col = 'æ°å'
    
    if not active_engineers_df.empty:
        if 'æ°å' in active_engineers_df.columns:
            name_col = 'æ°å'
        else:
            name_col = active_engineers_df.columns[0]
        
        raw_names = active_engineers_df[name_col].dropna().astype(str).unique().tolist()
        active_names = sorted(raw_names)

        # è³‡æ ¼ãƒªã‚¹ãƒˆä½œæˆ
        qual_set = set()
        if 'ä¿æœ‰è³‡æ ¼' in active_engineers_df.columns:
            raw_vals = active_engineers_df['ä¿æœ‰è³‡æ ¼'].dropna().astype(str)
            for v in raw_vals:
                splits = re.split(r'[\s\u3000,ã€]+', v.strip())
                for s in splits:
                    if s: qual_set.add(s)
        active_quals = sorted(list(qual_set))

        # ãƒãƒƒãƒ—ã¨æ¤œç´¢ç”¨ãƒªã‚¹ãƒˆã®ä½œæˆ
        qual_col = 'ä¿æœ‰è³‡æ ¼' if 'ä¿æœ‰è³‡æ ¼' in active_engineers_df.columns else 'è³‡æ ¼'
        for index, row in active_engineers_df.iterrows():
            if pd.notnull(row[name_col]):
                nm = row[name_col]
                clean_key = clean_string_for_match(nm)
                
                raw_qual = ""
                if qual_col in row and pd.notnull(row[qual_col]):
                    val = row[qual_col]
                    if str(val).lower() != 'nan' and str(val).strip() != "":
                        raw_qual = str(val).strip().replace("\n", " ")
                
                engineer_map[clean_key] = raw_qual
                # ã“ã“ã§ãƒªã‚¹ãƒˆã‚’ä½œã‚‹ã“ã¨ã§ã€ã‚ã¨ã§ã“ã®ãƒªã‚¹ãƒˆã‚’ä½¿ã£ã¦ã‚»ãƒ«å†…ã‚’æ¤œç´¢ã™ã‚‹
                active_engineer_list.append((clean_key, nm))
    
    # éƒ¨åˆ†ä¸€è‡´ã§ã®èª¤çˆ†ã‚’é˜²ããŸã‚ã€åå‰ãŒé•·ã„é †ã«ã‚½ãƒ¼ãƒˆã—ã¦ãŠã
    active_engineer_list.sort(key=lambda x: len(x[0]), reverse=True)

    # ========================================================
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ UI
    # ========================================================
    st.sidebar.header("ğŸ” æ¤œç´¢æ¡ä»¶")

    if not df_search.empty:
        min_p = int(df_search['search_price'].min())
        max_p = int(df_search['search_price'].max())
        MAX_SAFE_PRICE = 1_000_000_000_000 
        if max_p > MAX_SAFE_PRICE: max_p = MAX_SAFE_PRICE
        if max_p <= min_p: max_p = min_p + 10000000
        
        kouji_types = df_search['å·¥ç¨®å'].dropna().unique().tolist() if 'å·¥ç¨®å' in df_search.columns else []
        raw_years = df_search['ç«£å·¥å¹´_val'].unique()
        years = sorted([int(y) for y in raw_years if y > 0], reverse=True)
        if not years: years = [2025]
    else:
        min_p, max_p = 0, 10000000
        kouji_types = []
        years = [2025]

    # Session State
    if 'price_key' not in st.session_state: st.session_state['price_key'] = (min_p, max_p)
    if 'type_key' not in st.session_state: st.session_state['type_key'] = []
    if 'start_year_key' not in st.session_state: st.session_state['start_year_key'] = years[-1] if years else 2000
    if 'end_year_key' not in st.session_state: st.session_state['end_year_key'] = years[0] if years else 2025
    if 'target_names_key' not in st.session_state: st.session_state['target_names_key'] = []
    if 'target_quals_key' not in st.session_state: st.session_state['target_quals_key'] = []
    if 'role_key' not in st.session_state: st.session_state['role_key'] = []
    if 'keyword_count' not in st.session_state: st.session_state['keyword_count'] = 1

    def clear_form():
        st.session_state['price_key'] = (min_p, max_p)
        st.session_state['type_key'] = []
        st.session_state['start_year_key'] = years[-1] if years else 2000
        st.session_state['end_year_key'] = years[0] if years else 2025
        st.session_state['target_names_key'] = []
        st.session_state['target_quals_key'] = []
        st.session_state['role_key'] = []
        for k in list(st.session_state.keys()):
            if k.startswith('kw_input_'): st.session_state[k] = ""

    if st.sidebar.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã®å†èª­ã¿è¾¼ã¿"):
        st.cache_data.clear()  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
        st.rerun()             # ç”»é¢ã‚’ãƒªãƒ­ãƒ¼ãƒ‰

    st.sidebar.button("æ¡ä»¶ãƒªã‚»ãƒƒãƒˆ", on_click=clear_form)

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆãƒ•ã‚©ãƒ¼ãƒ å¤–ã«é…ç½®ï¼‰
    st.sidebar.markdown("### ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ (ANDæ¡ä»¶)")
    keywords = []
    for i in range(st.session_state.get('keyword_count', 1)):
        val = st.sidebar.text_input(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ {i+1}", key=f"kw_input_{i}")
        if val: keywords.append(val)
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1ã®å¾Œã«è¿½åŠ ãƒœã‚¿ãƒ³ã‚’é…ç½®
        if i == 0:
            st.sidebar.button("ï¼‹ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ è¿½åŠ ", on_click=lambda: st.session_state.update({'keyword_count': st.session_state.get('keyword_count', 1) + 1}), key="add_keyword_btn")

    with st.sidebar.form("search_form"):
        step_val = 1000000
        if max_p - min_p < step_val: step_val = max(1, int((max_p - min_p) / 10))
        
        price_range = st.slider("é‡‘é¡ (å††ä»¥ä¸Š)", min_p, max_p, step=step_val, key='price_key')
        sel_types = st.multiselect("å·¥ç¨®", kouji_types, key='type_key')
        
        st.markdown("### ğŸ“… ç«£å·¥å¹´ã§çµã‚Šè¾¼ã¿")
        c1, c2 = st.columns(2)
        with c1: start_year = st.selectbox("é–‹å§‹å¹´", years, key='start_year_key')
        with c2: end_year = st.selectbox("çµ‚äº†å¹´", years, key='end_year_key')
            
        st.markdown("### ğŸ‘¤ æŠ€è¡“è€…åã§æ¤œç´¢ (è¤‡æ•°å¯)")
        target_names = st.multiselect("æŒ‡åæ¤œç´¢", active_names, key='target_names_key')

        st.markdown("### ğŸ« ä¿æœ‰è³‡æ ¼ã§æ¤œç´¢")
        target_quals = st.multiselect("è³‡æ ¼åã‚’é¸æŠ", active_quals, key='target_quals_key')
        
        role_cols = ['ç¾å ´ä»£ç†äºº', 'ç›£ç†æŠ€è¡“è€…', 'ä¸»ä»»æŠ€è¡“è€…', 'ç¾å ´æ‹…å½“è€…ï¼‘', 'ç¾å ´æ‹…å½“è€…ï¼’']
        avail_roles = [r for r in role_cols if r in df_search.columns]
        
        st.markdown("### è©³ç´°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
        sel_roles = st.multiselect("å¯¾è±¡å½¹è·", avail_roles, key='role_key')

        search_btn = st.form_submit_button("æ¤œç´¢")

    # ========================================================
    # æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ã¨çµæœè¡¨ç¤ºï¼ˆã“ã“ãŒå¤§ããå¤‰ã‚ã‚Šã¾ã—ãŸï¼‰
    # ========================================================
    if df_search.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        # æ¤œç´¢æ™‚ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å†å–å¾—ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰ï¼‰
        search_keywords = []
        for i in range(st.session_state.get('keyword_count', 1)):
            kw_val = st.session_state.get(f'kw_input_{i}', '')
            if kw_val: search_keywords.append(kw_val)
        
        # 1. ãƒ‡ãƒ¼ã‚¿ã®çµã‚Šè¾¼ã¿
        df_res = df_search[
            (df_search['search_price'] >= price_range[0]) & 
            (df_search['search_price'] <= price_range[1])
        ]
        if sel_types: df_res = df_res[df_res['å·¥ç¨®å'].isin(sel_types)]
        if 'ç«£å·¥å¹´_val' in df_res.columns:
            df_res = df_res[(df_res['ç«£å·¥å¹´_val'] >= start_year) & (df_res['ç«£å·¥å¹´_val'] <= end_year)]
        
        # 2. æ¤œç´¢å¯¾è±¡æŠ€è¡“è€…ã®æ±ºå®š
        search_target_list = [] # (clean_name, display_name) ã®ãƒªã‚¹ãƒˆ
        
        # æŒ‡åæ¤œç´¢ãƒ»è³‡æ ¼æ¤œç´¢ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
        requested_names = list(target_names)
        if target_quals and not active_engineers_df.empty:
             if 'ä¿æœ‰è³‡æ ¼' in active_engineers_df.columns:
                 def check_qual_contain(val):
                     if pd.isnull(val): return False
                     val_str = str(val)
                     norm_val = normalize_text(val_str)
                     tokens = set(re.split(r'[\s\u3000]+', norm_val.strip()))
                     norm_targets = [normalize_text(t) for t in target_quals]
                     return not tokens.isdisjoint(norm_targets)
                 matched_engs = active_engineers_df[active_engineers_df['ä¿æœ‰è³‡æ ¼'].apply(check_qual_contain)]
                 if not matched_engs.empty:
                     requested_names.extend(matched_engs[name_col].dropna().astype(str).tolist())
        
        requested_names = list(set(requested_names))

        if requested_names:
            # æŒ‡å®šãŒã‚ã‚‹å ´åˆã¯ã€ãã®äººãŸã¡ã ã‘ã‚’æ¢ã™
            for nm in requested_names:
                search_target_list.append((clean_string_for_match(nm), nm))
        else:
            # æŒ‡å®šãŒãªã„å ´åˆã¯ã€å…¨åœ¨ç±æŠ€è¡“è€…ã‚’æ¢ã™
            search_target_list = active_engineer_list

        # 3. æ¤œç´¢å®Ÿè¡Œï¼ˆåå‰ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰é«˜é€ŸåŒ–
        if requested_names:
            target_cleans = [t[0] for t in search_target_list]
            def check_row_contains_target(row):
                for r in avail_roles:
                    val = row.get(r)
                    if pd.notnull(val):
                        c_val = clean_string_for_match(val)
                        # å¯¾è±¡è€…ã®åå‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                        for t_clean in target_cleans:
                            if t_clean in c_val:
                                return True
                return False
            df_res = df_res[df_res.apply(check_row_contains_target, axis=1)]

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿
        if search_keywords:
            for k in search_keywords:
                k_norm = normalize_text(k)
                df_res = df_res[df_res['full_text_search'].str.contains(k_norm, na=False)]

        # --- é›†è¨ˆå‡¦ç† ---
        results = {}
        search_roles_final = sel_roles if sel_roles else avail_roles
        system_cols = ['search_price', 'full_text_search', 'ç«£å·¥æ—¥_dt', 'ç«£å·¥å¹´_val']

        for idx, row in df_res.iterrows():
            for role in search_roles_final:
                raw_val = row.get(role)
                if pd.isnull(raw_val) or str(raw_val).strip() == "":
                    continue
                
                # ã‚»ãƒ«ã®å†…å®¹ã‚’æ­£è¦åŒ–ï¼ˆã‚¹ãƒšãƒ¼ã‚¹å‰Šé™¤ï¼‰
                # ä¾‹: "ãˆ±å¢—æ¸•çµ„ã€€é«˜æ©‹ä¿¡è¡Œ" -> "ãˆ±å¢—æ¸•çµ„é«˜æ©‹ä¿¡è¡Œ"
                cell_clean = clean_string_for_match(raw_val)
                
                # ã€é‡è¦ã€‘ã‚»ãƒ«ã®ä¸­ã«ã€æ¤œç´¢å¯¾è±¡ã®æŠ€è¡“è€…åãŒåŸ‹ã¾ã£ã¦ã„ã‚‹ã‹ç¢ºèª
                # search_target_list ã¯åœ¨ç±è€…ï¼ˆã¾ãŸã¯æŒ‡åã•ã‚ŒãŸäººï¼‰ã®ã¿
                for eng_clean, eng_display in search_target_list:
                    
                    if eng_clean in cell_clean:
                        
                        # è¡¨ç¤ºå¯¾è±¡ã‹ã©ã†ã‹ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¡ä»¶ãªã©ï¼‰
                        is_display_target = True
                        if search_keywords:
                            for k in search_keywords:
                                if normalize_text(k) not in row['full_text_search']:
                                     is_display_target = False
                                     break
                        
                        if is_display_target:
                            if eng_display not in results:
                                p_qual = engineer_map.get(eng_clean, "")
                                results[eng_display] = {"qualification": p_qual, "projects": []}
                            
                            item = row.to_dict()
                            item['å½¹å‰²'] = role
                            results[eng_display]["projects"].append(item)

        st.subheader(f"æ¤œç´¢çµæœ: {len(results)} å")
        st.write("---")
        
        for name in sorted(results.keys()):
            data = results[name]
            qual_display = data['qualification']
            if qual_display and qual_display.lower() != 'nan':
                st.markdown(f"### ğŸ‘¤ {name} ã€” {qual_display} ã€•")
            else:
                st.markdown(f"### ğŸ‘¤ {name}")

            p_df = pd.DataFrame(data['projects'])
            if not p_df.empty:
                if 'search_price' in p_df.columns:
                    p_df = p_df.sort_values('search_price', ascending=False)
                
                # ã‚«ãƒ©ãƒ æ•´ç†
                all_cols = p_df.columns.tolist()
                orig_csv_cols = [c for c in df_kouji_raw.columns if c not in system_cols]
                final_order = ['å½¹å‰²']
                for c in orig_csv_cols:
                    if c in p_df.columns: final_order.append(c)
                for c in all_cols:
                    if c not in final_order and c not in system_cols: final_order.append(c)
                
                display_df = p_df[final_order].copy()
                for col in display_df.columns:
                    if 'æ—¥' in col:
                         display_df[col] = pd.to_datetime(display_df[col], errors='coerce').dt.strftime('%Y/%m/%d').fillna('')

                st.dataframe(display_df, use_container_width=True, hide_index=True)
            st.markdown("---")
# --- ã‚¿ãƒ–2: å·¥äº‹ç™»éŒ² ---
with tab2:
    st.header("âœï¸ å·¥äº‹å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®ç®¡ç†")
    st.info("ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ãƒ»ä¿®æ­£ã‚’è¡Œã„ã€Œä¿å­˜ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚ï¼ˆä¿å­˜ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¾ã§åæ˜ ã•ã‚Œã¾ã›ã‚“ï¼‰")

    k_col_cfg = {}
    if not df_kouji_raw.empty:
        for c in df_kouji_raw.columns:
            if "æ—¥" in c:
                k_col_cfg[c] = st.column_config.DateColumn(c, format="YYYY/MM/DD")

    # ã€ä¿®æ­£ã€‘ãƒ•ã‚©ãƒ¼ãƒ ã§å›²ã‚€ã“ã¨ã§ã€ç·¨é›†ä¸­ã®ãƒªãƒ­ãƒ¼ãƒ‰ã‚’é˜²ã
    with st.form("kouji_form"):
        if not df_kouji_raw.empty:
            edited_kouji = st.data_editor(
                df_kouji_raw,
                num_rows="dynamic",
                use_container_width=True,
                column_config=k_col_cfg,
                key="editor_kouji"
            )
        else:
            st.warning("å·¥äº‹ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚æ–°è¦ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")
            edited_kouji = pd.DataFrame()

        # ãƒœã‚¿ãƒ³ã‚’ form_submit_button ã«å¤‰æ›´
        submit_btn = st.form_submit_button("ğŸ’¾ å·¥äº‹ãƒ‡ãƒ¼ã‚¿ã‚’ä¸Šæ›¸ãä¿å­˜", type="primary")

    if submit_btn:
        if not edited_kouji.empty:
            if save_kouji(edited_kouji):
                st.success(f"ã‚·ãƒ¼ãƒˆã€Œ{KOUJI_SHEET}ã€ã«ä¸Šæ›¸ãä¿å­˜ã—ã¾ã—ãŸï¼")
                st.cache_data.clear()
                # ä¿å­˜å®Œäº†å¾Œã«ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ï¼ˆã“ã‚Œã§æ¤œç´¢ç”»é¢ï¼Tab1ã«æˆ»ã‚Šã¾ã™ï¼‰
                st.rerun()# --- ã‚¿ãƒ–3: æŠ€è¡“è€…ç™»éŒ² ---

# --- ã‚¿ãƒ–3: æŠ€è¡“è€…ç™»éŒ² ---
with tab3:
    st.header("ğŸ‘¤ æŠ€è¡“è€…æƒ…å ±ã®ç®¡ç†")
    st.info("æŠ€è¡“è€…ã®è¿½åŠ ãƒ»ä¿®æ­£ã‚’è¡Œã„ã€Œä¿å­˜ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚ï¼ˆä¿å­˜ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¾ã§åæ˜ ã•ã‚Œã¾ã›ã‚“ï¼‰")

    e_col_cfg = {
        "åœ¨ç±çŠ¶æ³": st.column_config.CheckboxColumn("åœ¨ç±", default=True),
        "æŠ€è¡“è€…ID": st.column_config.TextColumn("æŠ€è¡“è€…ID", width="medium", required=True),
        "ä¿æœ‰è³‡æ ¼": st.column_config.TextColumn("ä¿æœ‰è³‡æ ¼", width="large"),
    }
    if not df_eng_raw.empty:
        for c in df_eng_raw.columns:
            if "æ—¥" in c:
                e_col_cfg[c] = st.column_config.DateColumn(c, format="YYYY/MM/DD")

    # ã€ä¿®æ­£ã€‘ãƒ•ã‚©ãƒ¼ãƒ ã§å›²ã‚€ã“ã¨ã§ã€ç·¨é›†ä¸­ã®ãƒªãƒ­ãƒ¼ãƒ‰ã‚’é˜²ã
    with st.form("engineer_form"):
        if not df_eng_raw.empty:
            hide_cols = ['è³‡æ ¼', 'è³‡æ ¼åç§°']
            all_cols = df_eng_raw.columns.tolist()
            display_cols = [c for c in all_cols if c not in hide_cols]

            edited_eng = st.data_editor(
                df_eng_raw,
                column_order=display_cols,
                num_rows="dynamic",
                column_config=e_col_cfg,
                use_container_width=True,
                key="editor_eng"
            )
        else:
            st.warning("æŠ€è¡“è€…ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚")
            edited_eng = pd.DataFrame()
        
        # ãƒœã‚¿ãƒ³ã‚’ form_submit_button ã«å¤‰æ›´
        submit_btn_eng = st.form_submit_button("ğŸ’¾ æŠ€è¡“è€…ãƒ‡ãƒ¼ã‚¿ã‚’ä¸Šæ›¸ãä¿å­˜", type="primary")

    if submit_btn_eng:
        if not edited_eng.empty:
            if save_engineer(edited_eng):
                st.success(f"ã‚·ãƒ¼ãƒˆã€Œ{ENGINEER_SHEET}ã€ã«ä¸Šæ›¸ãä¿å­˜ã—ã¾ã—ãŸï¼")
                st.cache_data.clear()
                # ä¿å­˜å®Œäº†å¾Œã«ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ï¼ˆã“ã‚Œã§æ¤œç´¢ç”»é¢ï¼Tab1ã«æˆ»ã‚Šã¾ã™ï¼‰
                st.rerun()